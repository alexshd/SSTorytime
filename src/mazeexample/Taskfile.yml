version: "3"

# Taskfile for mazeexample project
# This file provides tasks for building, testing, and benchmarking
# the maze solving implementation using bidirectional wavefront search

vars:
  PACKAGE: main/mazeexample/maze
  BINARY: mazeexample
  BENCHMARK_BASELINE: benchmarks/benchmark_baseline.txt
  BENCHMARK_NEW: benchmarks/benchmark_new.txt
  UI_DIR: ui
  RESULTS_JSON: ui/results.json
  VIEWER_HTML: ui/viewer.html
  DOCS_DIR: docs/godoc
  COVERAGE_FILE: coverage.out
  COVERAGE_HTML: coverage.html

tasks:
  default:
    desc: Show available tasks
    cmds:
      - task --list
    silent: true

  build:
    desc: Build the mazeexample binary
    cmds:
      - go build -o {{.BINARY}} -v .
    sources:
      - "*.go"
      - "maze/*.go"
    generates:
      - "{{.BINARY}}"

  run:
    desc: Build and run the maze solver (text output)
    deps: [build]
    cmds:
      - ./{{.BINARY}}

  run-json:
    desc: Build and run with JSON output
    deps: [build]
    cmds:
      - ./{{.BINARY}} --json

  visualize:
    desc: Generate JSON results and prepare for visualization
    deps: [build]
    cmds:
      - echo "ðŸ§© Maze Solver Visualization"
      - echo ""
      - echo "Generating JSON output..."
      - ./{{.BINARY}} --json > {{.RESULTS_JSON}}
      - echo "âœ“ Results generated in {{.RESULTS_JSON}}"
      - echo ""
      - |
        if command -v jq &> /dev/null; then
          echo "Statistics:"
          cat {{.RESULTS_JSON}} | jq '.statistics'
          echo ""
          echo "Solution Summary:"
          cat {{.RESULTS_JSON}} | jq '.solutions[] | {id, type, total_length}'
        else
          echo "Statistics and solutions generated (install 'jq' for pretty output)"
        fi
      - echo ""
      - echo "âœ“ All files generated successfully!"
      - echo ""
      - echo "Next steps:"
      - echo "  1. Open {{.VIEWER_HTML}} in your web browser"
      - echo "     Linux - xdg-open {{.VIEWER_HTML}}"
      - echo "     macOS - open {{.VIEWER_HTML}}"
      - echo "     Windows - start {{.VIEWER_HTML}}"
      - echo "  2. Or drag {{.VIEWER_HTML}} into your browser"
      - echo "  3. The viewer will automatically load results.json"
      - echo ""
      - echo "Files generated in {{.UI_DIR}}/ directory"

  view:
    desc: Open the visualization in the default browser
    deps: [visualize]
    cmds:
      - |
        if command -v xdg-open &> /dev/null; then
          xdg-open {{.VIEWER_HTML}}
        elif command -v open &> /dev/null; then
          open {{.VIEWER_HTML}}
        elif command -v start &> /dev/null; then
          start {{.VIEWER_HTML}}
        else
          echo "Please open {{.VIEWER_HTML}} manually in your browser"
        fi

  serve:
    desc: Serve visualization with auto-reload (requires Python)
    deps: [visualize]
    cmds:
      - echo "Starting HTTP server on http://localhost:8000"
      - echo "Open http://localhost:8000/{{.VIEWER_HTML}} in your browser"
      - echo "Press Ctrl+C to stop"
      - echo ""
      - |
        if command -v python3 &> /dev/null; then
          python3 -m http.server 8000
        elif command -v python &> /dev/null; then
          python -m SimpleHTTPServer 8000
        else
          echo "Python not found. Please install Python or use 'task view' instead"
          exit 1
        fi

  clean:
    desc: Clean build artifacts and test files
    cmds:
      - rm -f {{.BINARY}}
      - rm -f {{.BENCHMARK_NEW}}
      - rm -f {{.COVERAGE_FILE}} {{.COVERAGE_HTML}}
      - rm -f cpu.prof mem.prof
      - go clean -testcache
      - echo "âœ“ Cleaned build artifacts and test cache"

  test:
    desc: Run all tests
    cmds:
      - go test -C maze

  test-v:
    desc: Run all tests with verbose output (shows maze solving details)
    cmds:
      - go test -C maze -v

  test-run:
    desc: "Run a specific test (usage: task test-run TEST=TestVertex)"
    cmds:
      - go test -C maze -run {{.TEST}}
    vars:
      TEST: '{{.TEST | default "TestOpen"}}'

  test-coverage:
    desc: Run tests with coverage report
    cmds:
      - go test ./maze -cover
      - go test ./maze -coverprofile={{.COVERAGE_FILE}}
      - go tool cover -html={{.COVERAGE_FILE}} -o {{.COVERAGE_HTML}}
      - echo "âœ“ Coverage report generated at {{.COVERAGE_HTML}}"
      - |
        if command -v xdg-open &> /dev/null; then
          xdg-open {{.COVERAGE_HTML}} 2>/dev/null &
        elif command -v open &> /dev/null; then
          open {{.COVERAGE_HTML}} 2>/dev/null &
        fi

  test-coverage-func:
    desc: Run tests and show coverage by function
    cmds:
      - go test ./maze -coverprofile={{.COVERAGE_FILE}}
      - go tool cover -func={{.COVERAGE_FILE}}

  bench:
    desc: Run all benchmarks with memory stats
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$

  bench-v:
    desc: Run all benchmarks with verbose test output
    cmds:
      - go test -C maze -bench=. -benchmem

  bench-time:
    desc: "Run benchmarks with custom duration (usage: task bench-time TIME=5s)"
    cmds:
      - go test -C maze -bench=. -benchmem -benchtime={{.TIME}} -run=^$
    vars:
      TIME: '{{.TIME | default "5s"}}'

  bench-run:
    desc: "Run specific benchmark (usage: task bench-run BENCH=BenchmarkVertex)"
    cmds:
      - go test -C maze -bench={{.BENCH}} -benchmem -run=^$
    vars:
      BENCH: '{{.BENCH | default "BenchmarkVertex"}}'

  bench-core:
    desc: Run core benchmarks only (Open, Vertex, Edge, GraphBuilding, SolveMaze, MemoryAllocation)
    cmds:
      - go test -C maze -bench='Benchmark(Open|Vertex|Edge|GraphBuilding|SolveMaze|MemoryAllocation)' -benchmem -benchtime=1s -run=^$

  bench-save:
    desc: Save benchmark results to file
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$ > {{.BENCHMARK_BASELINE}}
      - echo "Benchmark baseline saved to {{.BENCHMARK_BASELINE}}"

  bench-compare:
    desc: Run benchmarks and compare with baseline (requires benchstat)
    deps: [bench-check-benchstat]
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$ > {{.BENCHMARK_NEW}}
      - benchstat {{.BENCHMARK_BASELINE}} {{.BENCHMARK_NEW}}
      - echo ""
      - echo "New results saved to {{.BENCHMARK_NEW}}"

  bench-check-benchstat:
    desc: Check if benchstat is installed
    cmds:
      - |
        if ! command -v benchstat &> /dev/null; then
          echo "benchstat not found. Installing..."
          go install golang.org/x/perf/cmd/benchstat@latest
        fi
    silent: true
    internal: true

  bench-cpu:
    desc: Run CPU profiling on benchmarks
    cmds:
      - go test -C maze -bench=. -benchmem -cpuprofile=cpu.prof -run=^$
      - echo "CPU profile saved to cpu.prof"
      - echo "Analyze with - go tool pprof cpu.prof"

  bench-mem:
    desc: Run memory profiling on benchmarks
    cmds:
      - go test -C maze -bench=. -benchmem -memprofile=mem.prof -run=^$
      - echo "Memory profile saved to mem.prof"
      - echo "Analyze with - go tool pprof mem.prof"

  verify:
    desc: Run build, test, and benchmarks to verify everything works
    cmds:
      - task: build
      - task: test
      - task: bench-core
      - echo ""
      - echo "âœ“ All verification steps passed!"

  ci:
    desc: Run CI pipeline (build, test with coverage, core benchmarks)
    cmds:
      - task: clean
      - task: build
      - task: test-coverage-func
      - task: bench-core
      - echo ""
      - echo "âœ“ CI pipeline completed successfully!"

  fmt:
    desc: Format Go code
    cmds:
      - go fmt ./...

  vet:
    desc: Run go vet
    cmds:
      - go vet ./...

  lint:
    desc: Run go vet and check formatting
    cmds:
      - task: fmt
      - task: vet
      - |
        if [ -n "$(gofmt -l .)" ]; then
          echo "Go code is not formatted. Run 'task fmt'"
          exit 1
        fi
      - echo "âœ“ Code is properly formatted and vetted"

  watch-test:
    desc: Watch for changes and run tests
    cmds:
      - |
        echo "Watching for changes... (Ctrl+C to stop)"
        while true; do
          go test ./maze
          inotifywait -q -e modify *.go maze/*.go 2>/dev/null || sleep 2
        done

  # Documentation tasks
  docs:
    desc: Generate all documentation (godoc + package docs)
    cmds:
      - task: docs-godoc
      - task: docs-serve-info

  docs-godoc:
    desc: Start godoc server to view package documentation
    cmds:
      - echo "ðŸ“š Starting godoc server..."
      - echo ""
      - echo "View documentation at:"
      - echo "  http://localhost:6060/pkg/main/mazeexample/maze/"
      - echo ""
      - echo "Press Ctrl+C to stop"
      - echo ""
      - |
        if command -v godoc &> /dev/null; then
          godoc -http=:6060
        else
          echo "godoc not found. Installing..."
          go install golang.org/x/tools/cmd/godoc@latest
          echo "âœ“ godoc installed"
          echo "Starting server..."
          godoc -http=:6060
        fi

  docs-serve-info:
    desc: Show information about viewing documentation
    cmds:
      - |
        echo "ðŸ“š Documentation Access"
        echo ""
        echo "To view Go documentation:"
        echo "  1. Run: task docs-godoc"
        echo "  2. Open: http://localhost:6060/pkg/main/mazeexample/maze/"
        echo ""
        echo "To view project documentation:"
        echo "  - README.md - Main project overview"
        echo "  - docs/TEST_README.md - Testing guide"
        echo "  - docs/JSON_VIEWER_README.md - Visualization guide"
        echo "  - docs/BENCHMARK_COMPARISON.md - Performance analysis"
        echo ""
        echo "To generate godoc markdown (requires go-md2man or similar):"
        echo "  go doc -all ./maze > docs/godoc/API.md"
    silent: true

  docs-pkg:
    desc: Generate package documentation (requires go doc)
    cmds:
      - mkdir -p {{.DOCS_DIR}}
      - go doc -all ./maze > {{.DOCS_DIR}}/API.txt
      - echo "âœ“ Package documentation saved to {{.DOCS_DIR}}/API.txt"
      - |
        if command -v go-md2man &> /dev/null; then
          go doc -all ./maze | go-md2man > {{.DOCS_DIR}}/API.md
          echo "âœ“ Markdown documentation saved to {{.DOCS_DIR}}/API.md"
        else
          echo "  (Install go-md2man for markdown format)"
        fi

  docs-clean:
    desc: Clean generated documentation
    cmds:
      - rm -rf {{.DOCS_DIR}}
      - echo "âœ“ Cleaned generated documentation"

  help:
    desc: Show detailed help information
    cmds:
      - |
        cat << 'EOF'
        Mazeexample Package Taskfile
        =============================

        Quick Start:
          task build       - Build the package
          task run         - Run the maze solver (text output)
          task visualize   - Generate JSON and prepare visualization
          task serve       - Serve visualization with HTTP server

        Visualization:
          task visualize   - Generate JSON results with statistics
          task serve       - Start HTTP server at localhost:8000
          task view        - Open viewer in default browser
          task run-json    - Run with JSON output only

        Testing:
          task test        - Run tests (quiet mode)
          task test-v      - Run tests with verbose output
          task test-run TEST=TestVertex - Run specific test
          task test-coverage - Generate HTML coverage report
          task test-coverage-func - Show coverage by function

        Benchmarking:
          task bench       - Run all benchmarks
          task bench-core  - Run core benchmarks only
          task bench-save  - Save baseline for comparison
          task bench-compare - Compare with baseline (needs benchstat)
          task bench-cpu   - Profile CPU usage
          task bench-mem   - Profile memory usage

        Documentation:
          task docs        - Show documentation access info
          task docs-godoc  - Start godoc server (http://localhost:6060)
          task docs-pkg    - Generate package API documentation
          task docs-clean  - Clean generated documentation

        Development:
          task verify      - Full verification (build + test + bench)
          task ci          - CI pipeline with coverage
          task lint        - Check code formatting and vet
          task fmt         - Format Go code
          task vet         - Run go vet
          task watch-test  - Auto-run tests on file changes

        Cleanup:
          task clean       - Remove build artifacts and test cache

        For more details:
          - docs/TEST_README.md - Testing guide
          - docs/BENCHMARK_COMPARISON.md - Performance analysis
          - task docs-godoc - View Go package documentation
        EOF
    silent: true

version: "3"

# Taskfile for mazeexample project
# This file provides tasks for building, testing, and benchmarking
# the maze solving implementation using bidirectional wavefront search

vars:
  PACKAGE: main/mazeexample/maze
  BINARY: mazeexample
  BENCHMARK_BASELINE: benchmark_baseline.txt
  BENCHMARK_NEW: benchmark_new.txt

tasks:
  default:
    desc: Show available tasks
    cmds:
      - task --list
    silent: true

  build:
    desc: Build the mazeexample binary
    cmds:
      - go build -o {{.BINARY}} -v .
    sources:
      - "*.go"
      - "maze/*.go"
    generates:
      - "{{.BINARY}}"

  run:
    desc: Build and run the maze solver (text output)
    deps: [build]
    cmds:
      - ./{{.BINARY}}

  run-json:
    desc: Build and run with JSON output
    deps: [build]
    cmds:
      - ./{{.BINARY}} --json

  visualize:
    desc: Generate JSON results and prepare for visualization
    deps: [build]
    cmds:
      - echo "ðŸ§© Maze Solver Visualization"
      - echo ""
      - echo "Generating JSON output..."
      - ./{{.BINARY}} --json > results.json
      - echo "âœ“ Results generated"
      - echo ""
      - |
        if command -v jq &> /dev/null; then
          echo "Statistics:"
          cat results.json | jq '.statistics'
          echo ""
          echo "Solution Summary:"
          cat results.json | jq '.solutions[] | {id, type, total_length}'
        else
          echo "Statistics and solutions generated (install 'jq' for pretty output)"
        fi
      - echo ""
      - echo "âœ“ All files generated successfully!"
      - echo ""
      - echo "Next steps:"
      - echo "  1. Open viewer.html in your web browser"
      - echo "     Linux - xdg-open viewer.html"
      - echo "     macOS - open viewer.html"
      - echo "     Windows - start viewer.html"
      - echo "  2. Or drag viewer.html into your browser"
      - echo "  3. The viewer will automatically load results.json"
      - echo ""
      - echo "Files generated in current directory"

  view:
    desc: Open the visualization in the default browser
    deps: [visualize]
    cmds:
      - |
        if command -v xdg-open &> /dev/null; then
          xdg-open viewer.html
        elif command -v open &> /dev/null; then
          open viewer.html
        elif command -v start &> /dev/null; then
          start viewer.html
        else
          echo "Please open viewer.html manually in your browser"
        fi

  serve:
    desc: Serve visualization with auto-reload (requires Python)
    deps: [visualize]
    cmds:
      - echo "Starting HTTP server on http://localhost:8000"
      - echo "Open http://localhost:8000/viewer.html in your browser"
      - echo "Press Ctrl+C to stop"
      - echo ""
      - |
        if command -v python3 &> /dev/null; then
          python3 -m http.server 8000
        elif command -v python &> /dev/null; then
          python -m SimpleHTTPServer 8000
        else
          echo "Python not found. Please install Python or use 'task view' instead"
          exit 1
        fi

  clean:
    desc: Clean build artifacts and test files
    cmds:
      - rm -f {{.BINARY}}
      - rm -f {{.BENCHMARK_NEW}}
      - go clean -testcache

  test:
    desc: Run all tests
    cmds:
      - go test -C maze

  test-v:
    desc: Run all tests with verbose output (shows maze solving details)
    cmds:
      - go test -C maze -v

  test-run:
    desc: "Run a specific test (usage: task test-run TEST=TestVertex)"
    cmds:
      - go test -C maze -run {{.TEST}}
    vars:
      TEST: '{{.TEST | default "TestOpen"}}'

  test-coverage:
    desc: Run tests with coverage report
    cmds:
      - go test -C maze -cover
      - go test -C maze -coverprofile=coverage.out
      - go tool cover -html=coverage.out -o coverage.html
      - echo "Coverage report generated at coverage.html"

  test-coverage-func:
    desc: Run tests and show coverage by function
    cmds:
      - go test -C maze -coverprofile=coverage.out
      - go tool cover -func=coverage.out

  bench:
    desc: Run all benchmarks with memory stats
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$

  bench-v:
    desc: Run all benchmarks with verbose test output
    cmds:
      - go test -C maze -bench=. -benchmem

  bench-time:
    desc: "Run benchmarks with custom duration (usage: task bench-time TIME=5s)"
    cmds:
      - go test -C maze -bench=. -benchmem -benchtime={{.TIME}} -run=^$
    vars:
      TIME: '{{.TIME | default "5s"}}'

  bench-run:
    desc: "Run specific benchmark (usage: task bench-run BENCH=BenchmarkVertex)"
    cmds:
      - go test -C maze -bench={{.BENCH}} -benchmem -run=^$
    vars:
      BENCH: '{{.BENCH | default "BenchmarkVertex"}}'

  bench-core:
    desc: Run core benchmarks only (Open, Vertex, Edge, GraphBuilding, SolveMaze, MemoryAllocation)
    cmds:
      - go test -C maze -bench='Benchmark(Open|Vertex|Edge|GraphBuilding|SolveMaze|MemoryAllocation)' -benchmem -benchtime=1s -run=^$

  bench-save:
    desc: Save benchmark results to file
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$ > {{.BENCHMARK_BASELINE}}
      - echo "Benchmark baseline saved to {{.BENCHMARK_BASELINE}}"

  bench-compare:
    desc: Run benchmarks and compare with baseline (requires benchstat)
    deps: [bench-check-benchstat]
    cmds:
      - go test -C maze -bench=. -benchmem -run=^$ > {{.BENCHMARK_NEW}}
      - benchstat {{.BENCHMARK_BASELINE}} {{.BENCHMARK_NEW}}
      - echo ""
      - echo "New results saved to {{.BENCHMARK_NEW}}"

  bench-check-benchstat:
    desc: Check if benchstat is installed
    cmds:
      - |
        if ! command -v benchstat &> /dev/null; then
          echo "benchstat not found. Installing..."
          go install golang.org/x/perf/cmd/benchstat@latest
        fi
    silent: true
    internal: true

  bench-cpu:
    desc: Run CPU profiling on benchmarks
    cmds:
      - go test -C maze -bench=. -benchmem -cpuprofile=cpu.prof -run=^$
      - echo "CPU profile saved to cpu.prof"
      - echo "Analyze with - go tool pprof cpu.prof"

  bench-mem:
    desc: Run memory profiling on benchmarks
    cmds:
      - go test -C maze -bench=. -benchmem -memprofile=mem.prof -run=^$
      - echo "Memory profile saved to mem.prof"
      - echo "Analyze with - go tool pprof mem.prof"

  verify:
    desc: Run build, test, and benchmarks to verify everything works
    cmds:
      - task: build
      - task: test
      - task: bench-core
      - echo ""
      - echo "âœ“ All verification steps passed!"

  ci:
    desc: Run CI pipeline (build, test with coverage, core benchmarks)
    cmds:
      - task: clean
      - task: build
      - task: test-coverage-func
      - task: bench-core
      - echo ""
      - echo "âœ“ CI pipeline completed successfully!"

  fmt:
    desc: Format Go code
    cmds:
      - go fmt ./...

  vet:
    desc: Run go vet
    cmds:
      - go vet ./...

  lint:
    desc: Run go vet and check formatting
    cmds:
      - task: fmt
      - task: vet
      - |
        if [ -n "$(gofmt -l .)" ]; then
          echo "Go code is not formatted. Run 'task fmt'"
          exit 1
        fi
      - echo "âœ“ Code is properly formatted and vetted"

  watch-test:
    desc: Watch for changes and run tests
    cmds:
      - |
        echo "Watching for changes... (Ctrl+C to stop)"
        while true; do
          go test
          inotifywait -q -e modify *.go 2>/dev/null || sleep 2
        done

  help:
    desc: Show detailed help information
    cmds:
      - |
        cat << 'EOF'
        Mazeexample Package Taskfile
        =============================

        Quick Start:
          task build       - Build the package
          task run         - Run the maze solver (text output)
          task visualize   - Generate JSON and prepare visualization
          task serve       - Serve visualization with HTTP server

        Visualization:
          task visualize   - Generate JSON results with statistics
          task serve       - Start HTTP server at localhost:8000
          task view        - Open viewer in default browser
          task run-json    - Run with JSON output only

        Testing:
          task test        - Run tests (quiet mode)
          task test-v      - Run tests with verbose output
          task test-run TEST=TestVertex - Run specific test
          task test-coverage - Generate HTML coverage report

        Benchmarking:
          task bench       - Run all benchmarks
          task bench-core  - Run core benchmarks only
          task bench-save  - Save baseline for comparison
          task bench-compare - Compare with baseline (needs benchstat)
          task bench-cpu   - Profile CPU usage
          task bench-mem   - Profile memory usage

        Development:
          task verify      - Full verification (build + test + bench)
          task ci          - CI pipeline with coverage
          task lint        - Check code formatting and vet
          task watch-test  - Auto-run tests on file changes

        Cleanup:
          task clean       - Remove test artifacts

        For more details, see TEST_README.md
        EOF
    silent: true
